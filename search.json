[
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Midsprint",
    "section": "Education",
    "text": "Education\nMSc Exercise Science\nUniversity of Montreal | Montreal, QC\nBSc Kinesiology & Statistics\nSimon Fraser University | Vancouver, BC"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Midsprint",
    "section": "Experience",
    "text": "Experience\nSports Science Intern | Montreal Canadiens Hockey Club (NHL)\nSept 2020 - August 2022\nSports Science Consultant | Various collegiate and professional teams\nSept 2019 - Present"
  },
  {
    "objectID": "blog/bdb_21.html",
    "href": "blog/bdb_21.html",
    "title": "Big Data Bowl 2021 Submission",
    "section": "",
    "text": "The 40-yard dash is one of the most exciting events tested at the NFL Combine. Prospects set-up in a three-point stance and, after a brief pause, start of their own volition. Time begins when the hand is released from the ground and stops when the player breaks the plane at 40 yards. Sprint times are typically five seconds or less.\nIn those five seconds, players display their ability to produce force and power. Within position groups, the fastest players are drafted earlier and have more career success. Unfortunately, much of the data surrounding their career success and abilities are descriptive in nature. Research has also shown that the fastest 40-yard splits are run by players with the greatest top-speeds. Yet there is very little evidence that the 40-yard dash translates to an athlete’s on-field mechanical sprint abilities.\nPlayers rarely reach their top-speed during games. Passing plays that last 4 to 6 seconds challenge receivers to create space between themselves and the defender. It is their ability to juke, deke, cut, and feint that creates this space. Conversely, defenders attempt to remain in proximity of the receiver by mirroring these changes in speed and direction. These factors affect a player’s ability to reach their top-speed.\nThis paper explores the relationship between an athlete’s sprint kinetics and pass completion rates. Specifically, it aims to explore whether modeling an athlete’s mechanical sprint profile to cover a given distance can influence pass outcomes. Background information on modeling an athlete’s mechanical sprint abilities is provided as a framework for new methodologies that can be applied in-game.\n\n\n\nFurusawa and colleagues (1927) first modeled sprint kinetics and kinematics by analyzing a sprinter’s center of mass while running. Their approach utilizing inverse dynamics was a simple method of assessing a sprinter’s biomechanical abilities and horizontal force production. The methods Furusawa and colleagues (1927) introduced remain steadfast in the face of technological advancements.\nModeling sprint kinetics provides sports scientists with insight into a player’s lower-body neuromuscular potential. For example, this information provides practitioners with the understanding of an athlete’s strengths and weaknesses. Currently, player profiling is impractical when working with positional tracking data. Game data does not often comprise of players reaching maximal speeds with maximal effort, a key factor in force-velocity-power profiling. Instead, researchers resort to profiling athletes at the Combine’s 40-yard dash event. They hope that these athlete profiles translate to in-game sprint performance.\nAn emerging field in sports science is in-situ player profiling. This concept employs positional tracking data to model a player’s force-velocity-power profile. Doing so provides insight into how events like the 40-yard dash translate to on-field mechanical sprint capabilities. Presently there is only one publication, a proof-of-concept in men’s professional soccer, that utilizes GPS data to model force-velocity profiles. This submission expands on the in-situ concept in professional American Football.\n\n\nThere is very little difference between prospects’ mechanical abilities; within all position groups, fast and slow players express the same sprint kinetics. The area in which players differ is their ability to accelerate. Furusawa et al. (1927) discovered that all humans reach their maximal speeds following the function:\n\\[\nv(t) = v_\\max \\cdot (1-e^\\frac{-t}{\\tau})\\\\\n\\]\nwhere \\(v(t)\\) represents an athlete’s velocity at time \\(t\\), \\(v_\\max\\) is an athlete’s maximum speed, and \\(\\tau\\) is the acceleration constant calculated:\n\\[\n\\tau = \\frac{v_\\max} {a_\\max}\n\\]\nwhere \\(a_\\max\\) is an athlete’s maximum acceleration. Building on the functions above, acceleration was modeled:\n\\[\na(t) = (\\frac {v_\\max}{\\tau}) \\cdot e^\\frac{-t}{\\tau}\\\\\n\\]\nwhere \\(a(t)\\) represents acceleration at time \\(t\\). Distance covered over time was also modeled:\n\\[\n\\Delta d (t)= v_\\max \\cdot ((t + \\tau) \\cdot e^\\frac{-t}{\\tau}) - (v_\\max \\cdot \\tau)\n\\]\nwhere \\(\\Delta d (t)\\) represents the distance travelled from point \\(d_0\\) to \\(d_i\\) at time \\(t\\).\nThe plot below shows two athletes: athlete A (red) is acceleration dominant whereas athlete B (black) is speed dominant. Although these athletes are different, it is the context of a play that displays their strengths.\n\n\n\n\n\n\n\n\n\n\nTo apply the models above, athletes must begin with zero velocity. This translates well to football because, all but one offensive athlete, cannot move until the ball is snapped. Unfortunately, unlike track sprinting, receivers rarely run linearly at maximal efforts. This hurdle makes it difficult to apply player profiling models in-game. If receivers are impeded during play, they risk losing speed and require more time to reach maximal velocity.\nThe concept is simple: which athlete reaches the intended destination first? Answering this question hinges on comparing athletes’ maximal potentials to cover distances in the time between the quarterback’s release of the ball and its arrival location. Thus, the models must be adjusted for time to be a function of velocity, acceleration, and distance.\nTime as a function of velocity, detailing how long it takes an athlete to reach a given speed:\n\\[\nv^{-1}(t) = ln[1- (\\frac{v}{v_\\max})]\\cdot\\tau\n\\]\nwhere \\(v\\) is an athlete’s current speed and \\(0 \\leq v < v_\\max\\).\nTime as a function of distance, illustrating how long it takes to reach a position in space:\n\\[\n\\Delta d^{-1}(t) = \\tau \\cdot W(-e^\\frac{1 - \\Delta d}{\\tau \\cdot v_\\max}) + \\tau + \\frac{\\Delta d}{v_\\max}\n\\]\nwhere \\(W\\) is the Lambert W function and defined as the inverse of \\(xe^x\\). That is:\n\\[\ny=W(x)\\iff x=ye^y\n\\]\nFinally, to model the speed reached, having travelled a given distance, the function is as follows:\n\\[\nv^{-1}(\\Delta d) = v_\\max \\cdot (t + \\tau  e^\\frac{-t}{\\tau}) - (v_\\max \\cdot \\tau)\n\\]\nwhere \\(t\\) is equal to \\(v^{-1}(t)\\).\n\n\n\nWhen the quarterback releases the ball, athletes rarely have zero velocity. The models above depend on individuals starting their run from a dead start. To understand how long it will take an athlete to cover a distance when in motion, the following function was derived:\n\\[\nv^{-1}(\\Delta d^{-1} (t)) = [\\tau \\cdot W(-e^\\frac{1 - \\Delta d + d_0}{\\tau \\cdot v_\\max}) + \\tau + \\frac{\\Delta d + d_0}{v_\\max}] - [\\tau \\cdot W(-e^\\frac{1 - d_0}{\\tau \\cdot v_\\max}) + \\tau + \\frac{d_0}{v_\\max}]\n\\]\nwhere \\(d_0\\) is equal to \\(v^{-1}(\\Delta d)\\) when \\(v = 0\\). This function assumes that athletes are running at maximal effort when spanning distances.\n\n\n\n\n\n\nThe defender closest to the receiver when the ball arrived was considered the primary defender. At the time of the ball’s release, players had unique locations on the field. Distances were calculated for the receiver and primary defender from their respective positions to where the ball arrived. The time interval between the release and arrival of the football was also recorded.\nThe assumption dictates that the nearest defender was also the primary defender. Although this assumption may not always apply, it simplifies analyses.\n\n\n\nBased on player speed and field position, the least amount of time required to travel from their current position to the ball’s destination was modeled. The time required to run this distance was based on the athlete’s unique force-velocity-power profile. As such, modeled outcomes are founded on the athlete arriving at the intended position with maximal effort and without impediment. Finally, pass outcomes were decided on whichever athlete arrived at the target destination first (offense: completion, defense: incompletion).\nAll analyses were completed in R 4.0.2.\n\n\n\n\nThere were 14,271 pass attempts that fit the inclusion criteria (11,022 completions, 3,249 incompletions). The average distance from the time-of-release to time-of-arrival was 5.32 yards and 7.89 yards for receivers and defenders, respectively. Receivers had a mean top speed of 10.6 yd/s and acceleration rate of 12.95 y/s/s (\\(\\tau\\) = 0.82 s), whereas defenders displayed a mean top speed of 10.26 yd/s and acceleration of 9.55 y/s/s (\\(\\tau\\) = 1.07 s). All details can be found in the table below.\nThe model correctly predicted pass outcomes 77.48% of the time (96.38% when the pass was successful, 14.41% when incomplete).\n\n\n\nThis paper was influenced by the current literature surrounding force-velocity-power profiling from the NFL Combine’s 40-yard dash test. It provides a novel approach to modeling athletes’ mechanical sprint capabilities that utilizes positional tracking data. Presently, there is only one publication that also attempts to model athletes in-situ.\nOutcomes were recorded as whichever athlete arrived first at the intended destination, based on their unique profile. The model accurately predicted pass outcomes nearly 4 out of 5 plays. Modeling pass outcomes in this paper presented unique challenges. The model cannot take game factors into account like interference, routes, contact, jukes, and dekes. Rather, it assumes that players are running linearly at maximal effort, without obstructions. As demonstrated, the outcomes heavily favoured pass completions. This can be attributed to the fact that the receiver knows their routes while defenders lag and must react to a receiver’s movements.\n\n\nSecondary analyses revealed that receivers are acceleration-dominant. Wide receivers and tight ends are heavily acceleration-dominant with \\(\\tau\\) below 0.90 s. All other offensive positions are also acceleration-dominant but to a lesser degree. Defensively, only cornerbacks and safeties are acceleration-dominant with very similar maximal speed, maximal acceleration, and \\(\\tau\\) values (0.83 s) as receivers. All other defensive positions display balanced or speed-dominant profiles.\n\n\n\nA large proportion of receivers decelerate when receiving a pass. This deceleration might be due to quarterbacks poorly leading receivers while in stride, or the receiver’s attempt to secure the football. It was also found that most defenders accelerate increase between ball release and arrival. Defenders were also found to increase their speeds between ball arrival and pass reception. These factors affected pass completion rates.\nThe model inaccurately predicts incompletions nearly 85% of the time. Further exploration identified that when the defender lags a receiver by less than 0.51 seconds to the point of arrival, as modeled when starting with zero velocity, it significantly decreases pass completion rates. Ergo, the proximity of a defender to the receiver coupled with the receiver’s deceleration dictates that the defense heavily influences pass outcomes between ball arrival and ball securement.\nThe model was rerun with the parameter that passes marked incomplete if the defender lags the receiver by a maximum of 0.51 seconds to the point of arrival. Results from this model increased the accuracy of identifying pass incompletions nearly 55%, and improved overall accuracy to 87.7%.\n\n\n\n\nThe 40-yard dash lasts 5 seconds or less. Much of the current research states that players with higher top speeds have better career success. The research does not explore the correlation between results at the Combine and on-field performance. This paper illustrates that wide receivers,tight ends, and corner acks heavily rely on their rates of acceleration in-game. Moreover, they rarely reach speeds on the field that were reached during the NFL Combine’s 40-yard dash test. Scouts should focus on an athlete’s rate of acceleration, not their top-speed or 40-yard split, when assessing athletic abilities. The formulas presented in this paper, and the accompanying R package midsprint, provides scouts with a novel method of assessing prospects."
  },
  {
    "objectID": "blog/blog-posts.html",
    "href": "blog/blog-posts.html",
    "title": "Blog Posts",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "blog/cardiac-drift.html#using-linear-regressions-to-model-cardia-drift-using-gps-data",
    "href": "blog/cardiac-drift.html#using-linear-regressions-to-model-cardia-drift-using-gps-data",
    "title": "Modelling Cardia Drift",
    "section": "Using Linear Regressions to Model Cardia Drift Using GPS Data",
    "text": "Using Linear Regressions to Model Cardia Drift Using GPS Data\n\nTracking Heart Rate\nSmart watches provide a somple method to track your heart rate throughout your day. Heart rate can provide feedback on sleep quality, training readiness, and overall recovery rates.\nEndurance athletes also use heart rate to estimate their max aerobic capacity (VO2max) and training intensity levels. During extended training sessions, there is an upward trend in athletes’ heart rate while working at the same intensities. This phenomenon is called cardiac drift.\n\n\nCardiac Drift\nThe upward trend in an athlete’s heart rate is multifactorial. The primary causes are dehydration and accumulation of metabolites.\nDehydration decreases blood plasma levels which forces the heart to work harder to deliver the necessary blood supply to the working muscles. The decreased blood plasma levels also affects the ability for the blood to accept metabolites that accumulate in working muscles.\nTo contract, muscles require energy. Endurance athletes predominantly rely on aerobic energy sources like carbohydrates and fat. The breakdown of these energy sources releases by-products that interfere with how efficient the muscle can contract. Therefore, it is important for these by-products to be expelled from the muscle cells. As water levels in the blood diminish, there is less drive for these by-products to exit the cell. Instead, they interfere with the mechanisms in the muscle cell that allow it to contract. This results in less forceful contractions and slower speeds.\nWhen an athlete wants to maintain a given pace, they need to overcome these by-products. To do so, they heart increases its pace to deliver more energy to the muscles and maintain the needed amount of force.\n\n\nLoad the packages\n\nlibrary(tidyverse) # for tidy code\n\n\n\nLoad the Data\nThe data is available on my GitHub repository and can be downloaded using the code below.\n\nurl <- \"https://github.com/aaronzpearson/midsprint-blog-data/raw/main/2017_01_31_18_36_44.csv\"\n\ngps_data <- read_csv(url)\n\nThe data structure:\n\nsummary(gps_data)\n\n      secs              km        power             hr             cad        \n Min.   :   0.0   Min.   :0   Min.   :  0.0   Min.   :113.0   Min.   :  0.00  \n 1st Qu.: 986.8   1st Qu.:0   1st Qu.:193.0   1st Qu.:177.0   1st Qu.: 92.00  \n Median :1973.5   Median :0   Median :206.0   Median :182.0   Median : 93.00  \n Mean   :1973.5   Mean   :0   Mean   :196.8   Mean   :178.7   Mean   : 90.95  \n 3rd Qu.:2960.2   3rd Qu.:0   3rd Qu.:216.0   3rd Qu.:185.0   3rd Qu.: 94.00  \n Max.   :3947.0   Max.   :0   Max.   :783.0   Max.   :190.0   Max.   :158.00  \n      alt          \n Min.   :-3.00000  \n 1st Qu.:-1.00000  \n Median : 0.00000  \n Mean   :-0.02067  \n 3rd Qu.: 1.00000  \n Max.   : 2.40000  \n\n\n\n\nCleaning the Data\nTo clean the data, we’ll remove when the athlete did not record any data.\n\ngps_data <- gps_data %>% # write over initial data set\n                         # not often recommended, but safe in this case\n    filter(\n        power > 0, # only keep data when the athlete was working\n        hr > 0 # remove data where the hr monitor was not being worn\n        )\n\n\n\nVisualizing the Data\nPlotting heart rate and power versus time.\n\noptions(repr.plot.width = 14, repr.plot.height = 8) # set plot size\n\ntheme_set(theme_minimal()) # set the global theme\n\nggplot(gps_data, aes(x = secs)) + # only set x-axis because of 2 dependent variables\n    geom_point(aes(y = power), color = \"black\") + \n    geom_point(aes(y = hr), colour = \"red\") + \n    xlab(\"Time (s)\") + ylab(\"Power (W), Heart Rate (bpm)\") \n\n\n\n\n\n\nThe Linear Model\nBelow is some code to visualize an athlete’s increase in heart-rate while working at nearly the same rate for 45 minutes.\n\nfit <- lm(hr ~ power:secs, data = gps_data) # only includes power-time interaction term\n\nsummary(fit) # overview of model fit\n\n\nCall:\nlm(formula = hr ~ power:secs, data = gps_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-83.284  -1.073   2.029   4.234  19.125 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 1.694e+02  2.605e-01   650.3   <2e-16 ***\npower:secs  2.522e-05  5.771e-07    43.7   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.43 on 3820 degrees of freedom\nMultiple R-squared:  0.3333,    Adjusted R-squared:  0.3332 \nF-statistic:  1910 on 1 and 3820 DF,  p-value: < 2.2e-16\n\n\nAlthough the goodness-of-fit isn’t great (r^2: 0.33, RSE: 8.43), it is inconsequential for the rest of the example.\nWe can add the fitted model to the current data set and then visualize the outputs.\n\ngps_data$fitted <- fitted(fit)\n\nBelow, you’ll note that the fitted model is not linear. This is because of the interaction between power and time. That is, when there is a spike in the interaction term, we’d anticipate a spike in heart rate as well.\nIf we did not include the interaction term and only included time, the model would be linear. This is seen in the green line that is fit using geom_smooth and the secs variable.\n\nggplot(gps_data, aes(x = secs)) + # only set x-axis because of 2 dependent variables\n    geom_point(aes(y = power), color = \"black\") + \n    geom_point(aes(y = hr), colour = \"red\") + \n    geom_point(aes(y = fitted), colour = \"blue\") + # fitted values\n    geom_smooth(aes(y = hr), colour = \"green\", size = 0.5, method = \"lm\") + # uses \"lm\" (linear model) to fit trendline\n    xlab(\"Time (s)\") + ylab(\"Power (W), Heart Rate (bpm)\")\n\n\n\n\n\n\nPredicted Outcomes\nUsing some quick math, we can estimate the athlete’s heart rate, Since there are spikes in power output, we’ll e conservative and use its 75th percentile.\n\nquantile(gps_data$power); quantile(gps_data$secs)\n\n  0%  25%  50%  75% 100% \n   7  195  206  217  783 \n\n\n     0%     25%     50%     75%    100% \n   0.00  979.25 1934.50 2914.75 3922.00 \n\n\nManually calculating the athlete’s fitted heart rate 3/4 through the race results in an increase of 16 which results in an increase from 169 to approximately 184 beats per minute while the athlete works at 217 kW.\nIn the end, we see that the athlete’s heart rate is expected to increase by 16 beats per minute after 45-50 minutes of sustained exercise.\n\n\nApplication\nThis information can be applied to the critical velocity model. The external expression of an increase in heart rate is the decrease in an athlete’s critical velocity. As such, we should expect to see that the athlete either relies more on anaerobic energy over time to sustain a given pace or that their pace decreases to maximize their use of aerobic energy."
  },
  {
    "objectID": "blog/fvp_split-apply-combine.html",
    "href": "blog/fvp_split-apply-combine.html",
    "title": "Profiling Multiple Athletes with fvp",
    "section": "",
    "text": "A while ago, I was asked how to use fvp to profile multiple athletes at once.\nAt the time, I had trouble working it out. Luckily, a current project required a similar task and I figured that I would try my hand at profiling multiple athletes using the fvp package again.\nAn oversight of mine is that the fvp package isn’t setup to work well with the tidyverse (this might change with future updates). Therefore, we can’t rely on the group_by(), nest() and map() combination to apply functions to multiple players at once. Instead, we can rely on base R’s equivalent of split-apply-combine which, in this case, will rely on the split(), lapply(), and rbind() functions.\nFor this blog post, we’ll look at two scenarios: 1. creating a data.frame per athlete that can then be called upon for further analyses, and 2. reporting summarized data as a single data.frame."
  },
  {
    "objectID": "blog/fvp_split-apply-combine.html#install-and-load-packages",
    "href": "blog/fvp_split-apply-combine.html#install-and-load-packages",
    "title": "Profiling Multiple Athletes with fvp",
    "section": "Install and Load Packages",
    "text": "Install and Load Packages\nInstall the fvp package if needed:\n\ndevtools::install_github(\"aaronzpearson/fvp\")\n\nLoad the packages\n\nlibrary(fvp) # for player profiling\nlibrary(tidyverse) # for initial data cleaning\nlibrary(data.table) # for efficient lodaing of the data"
  },
  {
    "objectID": "blog/fvp_split-apply-combine.html#load-data",
    "href": "blog/fvp_split-apply-combine.html#load-data",
    "title": "Profiling Multiple Athletes with fvp",
    "section": "Load Data",
    "text": "Load Data\nWe’ll use some of the NFL’s Big Data Bowl positional tracking data for the examples. We’ll import the data directly from GitHub by identifying the raw formatted data. Since I’ve worked with the data before, I know that there are only a handful of variables that we need or should have in the data set. The variables I selected are: x & y coordinates, speed (s), player IDs (nflId), and play IDs (playId.\nPlease note that this file is large and can take a minute or two to load.\n\nurl <- \"https://github.com/nfl-football-ops/Big-Data-Bowl/blob/master/Data/tracking_gameId_2017090700.csv?raw=true\"\nnfl <- data.table::fread(url) %>% \n  select(x, y, s, nflId, playId)\n\nhead(nfl)\n\n       x     y    s   nflId playId\n1: 41.56 16.54 3.91 2495340     44\n2: 41.95 16.62 4.28 2495340     44\n3: 42.40 16.73 4.66 2495340     44\n4: 42.85 16.82 5.04 2495340     44\n5: 43.36 16.92 5.39 2495340     44\n6: 43.87 17.02 5.60 2495340     44\n\n\nSince this data set doesn’t contain an acceleration (a) variable, we’ll need to add it in using mutate(). The data is at 10Hz, so we’ll take the difference of the players’ speed between time points and divide by 1/10. Also, I set it up so that acceleration is calculated per player, per play. This way, acceleration is not calculated as a continuous vector, rolling from player to player and play to play.\n\nnfl.clean = nfl %>% \n  group_by(nflId, playId) %>% \n  mutate(a = c(0, diff(s))/.1)\n\nhead(nfl.clean)\n\n# A tibble: 6 × 6\n# Groups:   nflId, playId [1]\n      x     y     s   nflId playId     a\n  <dbl> <dbl> <dbl>   <int>  <int> <dbl>\n1  41.6  16.5  3.91 2495340     44  0   \n2  42.0  16.6  4.28 2495340     44  3.7 \n3  42.4  16.7  4.66 2495340     44  3.8 \n4  42.8  16.8  5.04 2495340     44  3.8 \n5  43.4  16.9  5.39 2495340     44  3.50\n6  43.9  17.0  5.6  2495340     44  2.1"
  },
  {
    "objectID": "blog/fvp_split-apply-combine.html#select-player",
    "href": "blog/fvp_split-apply-combine.html#select-player",
    "title": "Profiling Multiple Athletes with fvp",
    "section": "Select Player",
    "text": "Select Player\nFor our examples, we’ll select the two players with the most playing time.\n\nplayers <- nfl.clean %>%\n  group_by(nflId) %>% \n  count(sort = TRUE) \n\ntop.players <- players$nflId[2:3] # players$nflId[1] is NA; represents the football\n\ntop.nfl <- nfl.clean %>% \n  filter(nflId %in% top.players)\n\nhead(top.nfl)\n\n# A tibble: 6 × 6\n# Groups:   nflId, playId [1]\n      x     y     s   nflId playId     a\n  <dbl> <dbl> <dbl>   <int>  <int> <dbl>\n1  42.2  32.2  4.83 2550257     44  0   \n2  42.6  31.9  5.05 2550257     44  2.20\n3  43.1  31.7  5.29 2550257     44  2.40\n4  43.7  31.6  5.55 2550257     44  2.60\n5  44.3  31.4  5.84 2550257     44  2.9 \n6  44.9  31.2  6.14 2550257     44  3"
  },
  {
    "objectID": "blog/fvp_split-apply-combine.html#split-the-data-set-per-player",
    "href": "blog/fvp_split-apply-combine.html#split-the-data-set-per-player",
    "title": "Profiling Multiple Athletes with fvp",
    "section": "Split the Data Set per Player",
    "text": "Split the Data Set per Player\nThe first step is to split() the data per player by their nflId. This is iterated over all players automatically. We’ll be left with a list of data.frames, so calling head() won’t work. Instead, we need to use the apply() family of functions to iterate a function over each element of the list.\n\nplayer.df <- split(top.nfl, top.nfl$nflId)\n\nlapply(player.df, head)\n\n$`2543699`\n# A tibble: 6 × 6\n# Groups:   nflId, playId [1]\n      x     y     s   nflId playId      a\n  <dbl> <dbl> <dbl>   <int>  <int>  <dbl>\n1  38.0  28.6  0.31 2543699    395  0    \n2  38.0  28.6  0.29 2543699    395 -0.200\n3  37.9  28.6  0.27 2543699    395 -0.200\n4  37.9  28.5  0.26 2543699    395 -0.100\n5  37.9  28.5  0.24 2543699    395 -0.200\n6  37.8  28.5  0.23 2543699    395 -0.100\n\n$`2550257`\n# A tibble: 6 × 6\n# Groups:   nflId, playId [1]\n      x     y     s   nflId playId     a\n  <dbl> <dbl> <dbl>   <int>  <int> <dbl>\n1  42.2  32.2  4.83 2550257     44  0   \n2  42.6  31.9  5.05 2550257     44  2.20\n3  43.1  31.7  5.29 2550257     44  2.40\n4  43.7  31.6  5.55 2550257     44  2.60\n5  44.3  31.4  5.84 2550257     44  2.9 \n6  44.9  31.2  6.14 2550257     44  3"
  },
  {
    "objectID": "blog/fvp_split-apply-combine.html#best-sprints-data-sets",
    "href": "blog/fvp_split-apply-combine.html#best-sprints-data-sets",
    "title": "Profiling Multiple Athletes with fvp",
    "section": "Best Sprints Data Sets",
    "text": "Best Sprints Data Sets\nFor this example, we’ll build a data set per player that returns their best on-field sprint. To do so, we’ll need the gps family of functions from fvp. Specifically, we’ll call the gps.best.sprint() function to return the player’s best observed, or actual, on-field sprint.\nThe gps.best.sprint() function takes on a few arguments: the game’s speed vector, the minimum starting speed for the sprint, and the percent of the player’s max speed that they must attain for us to consider the max effort sprint be achieved. Since player’s are often bumped at the beginning of each play, I set the minimum speed to 1 yd/s. I also set the percent of max speed to 95%. From experience, setting the percentage greater than 95% returns odd results because players don’t often reach their top speed more than 1-2 times per game.\nOne of the toughest parts of using lapply() is understanding the syntax. The first argument is the list onto which we want to apply a function. They second argument is the function we want to aply. That said, the function can either be pre-existing like in the example above. Otherwise, we can build a new function to incorporate different arguments.\nBelow, we must set the gps.best.sprint() function within another function. This way, we can consider x as the element of the list we want to apply the function. For this example, x represents the athletes’ data.frames.\n\nsprints <- lapply(player.df, \n                  function(x) gps.best.sprint(game.speed =  x$s, \n                                              min.speed = 1, \n                                              max.speed.threshold = 95)\n)\n\nlapply(sprints, head)\n\n$`2543699`\n  split.time observed.speed\n1        0.0           0.00\n2        0.1           0.87\n3        0.2           1.03\n4        0.3           1.25\n5        0.4           1.49\n6        0.5           1.75\n\n$`2550257`\n  split.time observed.speed\n1        0.0           0.00\n2        0.1           0.96\n3        0.2           1.66\n4        0.3           1.92\n5        0.4           2.19\n6        0.5           2.47\n\n\nWe can then plot the sprints by either combining the data sets and adding-in the player’s names, or by calling upon their position in the list of data.frames. Here, I went with the latter.\n\ntheme_set(theme_minimal())\n\nggplot(sprints[[1]], aes(x = split.time, y = observed.speed)) +\n  geom_point() +\n  geom_point(data = sprints[[2]], colour = \"red\") +\n  ylab(\"Observed Speed (yards/ s)\") +\n  xlab(\"Split Time (s)\")"
  },
  {
    "objectID": "blog/fvp_split-apply-combine.html#player-profile-data-set",
    "href": "blog/fvp_split-apply-combine.html#player-profile-data-set",
    "title": "Profiling Multiple Athletes with fvp",
    "section": "Player Profile Data Set",
    "text": "Player Profile Data Set\nIf we wanted to have a single data set that has all of the player’s summarized data, we can use a similar approach to the one above. The final step is to then re-combine the data so it is all in a single data frame using rbind().\nWe’ll use the same data split sets from above.\nIn this code chunk, we:\n* apply the speed-accel player profiling function (sa.player.profile) to each element of the list\n* use do.call() which also applies a function to each of the elements of the list\nWe need to use do.call() because it applies a function that isn’t typically allowed with lists. In this case, we built player profiles and used do.call() and rbind() to bind them back into a single data frame.\nIf we called rbind() directly, we’ll be returned an error.\n\nspeed.accel.profiles <- do.call(rbind,\n                           lapply(player.df, \n                          function(x) sa.player.profile(player.name = unique(x$nflId), \n                                                        game.data = sa.data(x$s, x$a)))\n)\n\nspeed.accel.profiles\n\n        player.name max.speed max.accel player.tau  r.square n.obervation\n2543699     2543699  10.85789  6.833430   1.588937 0.9546985           47\n2550257     2550257  11.39854  6.775927   1.682211 0.9519218           53\n\n\nUsing the speed-accel function on the players’ data sets, we are returned their summarized data. The speed-accel profiles look similar with player 2550257 slightly faster and player 2543699 slightly more accerlation dominant."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog Posts",
    "section": "",
    "text": "Modelling Cardiac Drift\nTry to predict the increase of an athlete’s heart rate over time during maintained aerobic conditioning.\nBDB ’21: 5 Seconds or Less\nBig Data Bowl 2021 submission that modelled athletes’ sprint abilities to predict passing outcomes. This submission earned an honourable mention."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Midsprint",
    "section": "Education",
    "text": "Education\nMSc Exercise Science\nUniversity of Montreal | Montreal, QC\nBSc Kinesiology & Statistics\nSimon Fraser University | Vancouver, BC"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Midsprint",
    "section": "Experience",
    "text": "Experience\nSports Science Intern | Montreal Canadiens Hockey Club (NHL)\nSept 2020 - August 2022\nSports Science Consultant | Various collegiate and professional teams\nSept 2019 - Present"
  }
]